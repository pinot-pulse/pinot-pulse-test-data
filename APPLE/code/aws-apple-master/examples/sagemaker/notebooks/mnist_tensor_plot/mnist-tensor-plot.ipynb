{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing Debugging Tensors of MXNet training"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overview"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "This demo is based on the SageMaker example documented here https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-debugger/mnist_tensor_plot. Because AWS@Apple has network isolation enforced in the SCP for SageMaker CreateTrainingJob, you cannot download public dataset using framework provided API directly. Here we demonstrate a way to leverage S3 data channels to avoid downloading from public. \n",
        "\n",
        "SageMaker Debugger is a new capability of Amazon SageMaker that allows debugging machine learning models. \n",
        "It lets you go beyond just looking at scalars like losses and accuracies during training and gives \n",
        "you full visibility into all the tensors 'flowing through the graph' during training. SageMaker Debugger helps you to monitor your training in near real time using rules and would provide you alerts, once it has detected an inconsistency in the training flow.\n",
        "\n",
        "Using SageMaker Debugger is a two step process: Saving tensors and Analysis. In this notebook we will run an MXNet training job and configure SageMaker Debugger to store all tensors from this job. Afterwards we will visualize those tensors in our notebook.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies\n",
        "Before we begin, let us install the library plotly if it is not already present in the environment.\n",
        "If the below cell installs the library for the first time, you'll have to restart the kernel and come back to the notebook. In addition to that, in order for our vizualiation to access tensors let's install smdebug - debugger library that provides API access to tensors emitted during training job."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "! python -m pip install plotly\n",
        "! python -m pip install smdebug"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (4.7.1)\n",
            "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from plotly) (1.14.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from plotly) (1.3.3)\n",
            "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
            "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
            "Requirement already satisfied: smdebug in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (0.8.1)\n",
            "Requirement already satisfied: boto3>=1.10.32 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from smdebug) (1.13.22)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from smdebug) (3.12.0)\n",
            "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from smdebug) (20.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from smdebug) (1.18.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.22 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (1.16.22)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.9.4)\n",
            "Requirement already satisfied: six>=1.9 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from protobuf>=3.6.0->smdebug) (1.14.0)\n",
            "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from protobuf>=3.6.0->smdebug) (46.1.3.post20200330)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from packaging->smdebug) (2.4.6)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from botocore<1.17.0,>=1.16.22->boto3>=1.10.32->smdebug) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from botocore<1.17.0,>=1.16.22->boto3>=1.10.32->smdebug) (2.8.1)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from botocore<1.17.0,>=1.16.22->boto3>=1.10.32->smdebug) (1.25.8)\n",
            "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
            "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure and run the training job\n",
        "\n",
        "Now we'll call the Sagemaker MXNet Estimator to kick off a training job with Debugger attached to it.\n",
        "\nThe `entry_point_script` points to the MXNet training script."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sagemaker\n",
        "from sagemaker.debugger import DebuggerHookConfig, CollectionConfig\n",
        "from sagemaker.mxnet import MXNet\n",
        "\n",
        "sagemaker_session = sagemaker.Session()\n",
        "\n",
        "entry_point_script = './scripts/mxnet_gluon_save_all_demo.py'\n",
        "hyperparameters = {'batch-size': 256}\n",
        "base_job_name = 'mnist-tensor-plot'\n",
        "\n",
        "# Make sure to set this to your bucket and location\n",
        "BUCKET_NAME = 'sagemaker-bhan-dev'\n",
        "LOCATION_IN_BUCKET = 'mnist-tensor-plot'\n",
        "s3_bucket_for_tensors = 's3://{BUCKET_NAME}/{LOCATION_IN_BUCKET}'.format(BUCKET_NAME=BUCKET_NAME, LOCATION_IN_BUCKET=LOCATION_IN_BUCKET)\n",
        "kms_key='db53dd38-c590-4dd2-9605-b35b668a3966' # Replace with your Sagemaker Notebook Instance KMS key\n",
        "\n",
        "estimator = MXNet(\n",
        "    role=sagemaker.get_execution_role(),\n",
        "    base_job_name=base_job_name,\n",
        "    train_instance_count=1,\n",
        "    train_instance_type='ml.m4.xlarge',\n",
        "    entry_point=entry_point_script,\n",
        "    framework_version='1.6.0',\n",
        "    train_max_run=3600,\n",
        "    sagemaker_session=sagemaker_session,\n",
        "    py_version='py3',\n",
        "    output_path=s3_bucket_for_tensors,\n",
        "    train_volume_kms_key=kms_key,\n",
        "    encrypt_inter_container_traffic=True,\n",
        "    subnets=['subnet-09b09827a04a561c0','subnet-033717301a9ddb40d'],\n",
        "    security_group_ids=['sg-0a58f487922c7143e'],\n",
        "    enable_network_isolation=True,\n",
        "    debugger_hook_config = DebuggerHookConfig(\n",
        "      s3_output_path=s3_bucket_for_tensors,  # Required\n",
        "      collection_configs=[\n",
        "          CollectionConfig(\n",
        "              name=\"all_tensors\",\n",
        "              parameters={\n",
        "                  \"include_regex\": \".*\",\n",
        "                  \"save_steps\": \"1, 2, 3\"\n",
        "              }\n",
        "          )\n",
        "      ]\n",
        "    )\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estimator described above will save all tensors of all layers during steps 1, 2 and 3. Now, we can prepare the data set and define the data channels. \n",
        "\n",
        "Because network isolated training job cannot download the required data set from public, we need to download them and upload to S3 in advance, then we can use them as data channels for training jobs.\n",
        "You may download the data set like below:\n",
        "```\n",
        "import mxnet    \n",
        "mnist_train = mxnet.gluon.data.vision.datasets.MNIST(root='/tmp', train=True)\n",
        "mnist_valid = mxnet.gluon.data.vision.FashionMNIST(root='/tmp', train=False)\n",
        "```\n",
        "This will download the training images/lables and validation images/labels under `/tmp`. You can upload the data set to S3 via boto3 API or aws CLI. Now we can define the data channels pointing to those S3 locations."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_channel = sagemaker.session.s3_input('s3://sagemaker-bhan-dev/mnist-datasets/mnist/train-images-idx3-ubyte.gz')\n",
        "train_label_channel = sagemaker.session.s3_input('s3://sagemaker-bhan-dev/mnist-datasets/mnist/train-labels-idx1-ubyte.gz')\n",
        "valid_data_channel = sagemaker.session.s3_input('s3://sagemaker-bhan-dev/mnist-datasets/fashion-mnist/t10k-images-idx3-ubyte.gz')\n",
        "valid_label_channel = sagemaker.session.s3_input('s3://sagemaker-bhan-dev/mnist-datasets/fashion-mnist/t10k-labels-idx1-ubyte.gz')\n",
        "\n",
        "data_channels = {\n",
        "    'train_data': train_data_channel, \n",
        "    'train_label': train_label_channel, \n",
        "    'valid_data': valid_data_channel, \n",
        "    'valid_label': valid_label_channel\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
            "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
            "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
            "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training jobs will download the data set defined in data channel to local and populate environment variable `SM_CHANNEL_{channel_name}` to point to these  local data location. In the example above, we defined 4 data channels: `train_data`, `train_label`, `valid_data`, `valid_label`, so a training job will populate 4 environment variables: `SM_CHANNEL_TRAIN_DATA`, `SM_CHANNEL_TRAIN_LABEL`, `SM_CHANNEL_VALID_DATA`, `SM_CHANNEL_VALID_LABEL`, and point them to the downloaded data set in local (by default it's under `/opt/ml/input/data/`). \n",
        "\n",
        "Now, we can start the training job with the `data_channels` as `inputs`.\n",
        "\nYou may check the `entry_point` script `./scripts/mxnet_gluon_save_all_demo.py` for how it references the data set in the training job for more details."
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimator.fit(inputs=data_channels,  logs=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
            "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020-06-16 22:03:07 Starting - Starting the training job...\n",
            "2020-06-16 22:03:09 Starting - Launching requested ML instances.........\n",
            "2020-06-16 22:04:42 Starting - Preparing the instances for training...\n",
            "2020-06-16 22:05:33 Downloading - Downloading input data...\n",
            "2020-06-16 22:05:56 Training - Downloading the training image..\n",
            "2020-06-16 22:06:16 Training - Training image download completed. Training in progress.\u001b[34m2020-06-16 22:06:17,413 sagemaker-containers INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
            "\u001b[34m2020-06-16 22:06:17,416 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2020-06-16 22:06:17,432 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{}', 'SM_USER_ENTRY_POINT': 'mxnet_gluon_save_all_demo.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{\"code\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train_data\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train_label\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid_data\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid_label\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"code\",\"train_data\",\"train_label\",\"valid_data\",\"valid_label\"]', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_NAME': 'mxnet_gluon_save_all_demo', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '4', 'SM_NUM_GPUS': '0', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': '/opt/ml/input/data/code/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"code\":\"/opt/ml/input/data/code\",\"train_data\":\"/opt/ml/input/data/train_data\",\"train_label\":\"/opt/ml/input/data/train_label\",\"valid_data\":\"/opt/ml/input/data/valid_data\",\"valid_label\":\"/opt/ml/input/data/valid_label\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"code\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train_data\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train_label\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid_data\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid_label\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mnist-tensor-plot-2020-06-16-22-03-06-879\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/input/data/code/sourcedir.tar.gz\",\"module_name\":\"mxnet_gluon_save_all_demo\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mxnet_gluon_save_all_demo.py\"}', 'SM_USER_ARGS': '[]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_VALID_LABEL': '/opt/ml/input/data/valid_label', 'SM_CHANNEL_CODE': '/opt/ml/input/data/code', 'SM_CHANNEL_TRAIN_LABEL': '/opt/ml/input/data/train_label', 'SM_CHANNEL_VALID_DATA': '/opt/ml/input/data/valid_data', 'SM_CHANNEL_TRAIN_DATA': '/opt/ml/input/data/train_data'}\u001b[0m\n",
            "\u001b[34m2020-06-16 22:06:17,464 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
            "\u001b[34mGenerating setup.py\u001b[0m\n",
            "\u001b[34m2020-06-16 22:06:17,464 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
            "\u001b[34m2020-06-16 22:06:17,465 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
            "\u001b[34m2020-06-16 22:06:17,465 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
            "\u001b[34m/usr/local/bin/python3.6 -m pip install . \u001b[0m\n",
            "\u001b[34mProcessing /tmp/tmphxfk5qbb/module_dir\u001b[0m\n",
            "\u001b[34mInstalling collected packages: default-user-module-name\n",
            "    Running setup.py install for default-user-module-name: started\n",
            "    Running setup.py install for default-user-module-name: finished with status 'done'\u001b[0m\n",
            "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
            "\u001b[34m2020-06-16 22:06:39,456 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2020-06-16 22:06:39,476 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2020-06-16 22:06:39,493 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2020-06-16 22:06:39,507 sagemaker-containers INFO     Invoking user script\n",
            "\u001b[0m\n",
            "\u001b[34mTraining Env:\n",
            "\u001b[0m\n",
            "\u001b[34m{\n",
            "    \"additional_framework_parameters\": {},\n",
            "    \"channel_input_dirs\": {\n",
            "        \"valid_label\": \"/opt/ml/input/data/valid_label\",\n",
            "        \"code\": \"/opt/ml/input/data/code\",\n",
            "        \"train_label\": \"/opt/ml/input/data/train_label\",\n",
            "        \"valid_data\": \"/opt/ml/input/data/valid_data\",\n",
            "        \"train_data\": \"/opt/ml/input/data/train_data\"\n",
            "    },\n",
            "    \"current_host\": \"algo-1\",\n",
            "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
            "    \"hosts\": [\n",
            "        \"algo-1\"\n",
            "    ],\n",
            "    \"hyperparameters\": {},\n",
            "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
            "    \"input_data_config\": {\n",
            "        \"valid_label\": {\n",
            "            \"TrainingInputMode\": \"File\",\n",
            "            \"S3DistributionType\": \"FullyReplicated\",\n",
            "            \"RecordWrapperType\": \"None\"\n",
            "        },\n",
            "        \"code\": {\n",
            "            \"TrainingInputMode\": \"File\",\n",
            "            \"S3DistributionType\": \"FullyReplicated\",\n",
            "            \"RecordWrapperType\": \"None\"\n",
            "        },\n",
            "        \"train_label\": {\n",
            "            \"TrainingInputMode\": \"File\",\n",
            "            \"S3DistributionType\": \"FullyReplicated\",\n",
            "            \"RecordWrapperType\": \"None\"\n",
            "        },\n",
            "        \"valid_data\": {\n",
            "            \"TrainingInputMode\": \"File\",\n",
            "            \"S3DistributionType\": \"FullyReplicated\",\n",
            "            \"RecordWrapperType\": \"None\"\n",
            "        },\n",
            "        \"train_data\": {\n",
            "            \"TrainingInputMode\": \"File\",\n",
            "            \"S3DistributionType\": \"FullyReplicated\",\n",
            "            \"RecordWrapperType\": \"None\"\n",
            "        }\n",
            "    },\n",
            "    \"input_dir\": \"/opt/ml/input\",\n",
            "    \"is_master\": true,\n",
            "    \"job_name\": \"mnist-tensor-plot-2020-06-16-22-03-06-879\",\n",
            "    \"log_level\": 20,\n",
            "    \"master_hostname\": \"algo-1\",\n",
            "    \"model_dir\": \"/opt/ml/model\",\n",
            "    \"module_dir\": \"/opt/ml/input/data/code/sourcedir.tar.gz\",\n",
            "    \"module_name\": \"mxnet_gluon_save_all_demo\",\n",
            "    \"network_interface_name\": \"eth0\",\n",
            "    \"num_cpus\": 4,\n",
            "    \"num_gpus\": 0,\n",
            "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
            "    \"output_dir\": \"/opt/ml/output\",\n",
            "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
            "    \"resource_config\": {\n",
            "        \"current_host\": \"algo-1\",\n",
            "        \"hosts\": [\n",
            "            \"algo-1\"\n",
            "        ],\n",
            "        \"network_interface_name\": \"eth0\"\n",
            "    },\n",
            "    \"user_entry_point\": \"mxnet_gluon_save_all_demo.py\"\u001b[0m\n",
            "\u001b[34m}\n",
            "\u001b[0m\n",
            "\u001b[34mEnvironment variables:\n",
            "\u001b[0m\n",
            "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
            "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
            "\u001b[34mSM_HPS={}\u001b[0m\n",
            "\u001b[34mSM_USER_ENTRY_POINT=mxnet_gluon_save_all_demo.py\u001b[0m\n",
            "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
            "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
            "\u001b[34mSM_INPUT_DATA_CONFIG={\"code\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train_data\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train_label\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid_data\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid_label\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
            "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
            "\u001b[34mSM_CHANNELS=[\"code\",\"train_data\",\"train_label\",\"valid_data\",\"valid_label\"]\u001b[0m\n",
            "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
            "\u001b[34mSM_MODULE_NAME=mxnet_gluon_save_all_demo\u001b[0m\n",
            "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
            "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
            "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
            "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
            "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
            "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
            "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
            "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
            "\u001b[34mSM_MODULE_DIR=/opt/ml/input/data/code/sourcedir.tar.gz\u001b[0m\n",
            "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"code\":\"/opt/ml/input/data/code\",\"train_data\":\"/opt/ml/input/data/train_data\",\"train_label\":\"/opt/ml/input/data/train_label\",\"valid_data\":\"/opt/ml/input/data/valid_data\",\"valid_label\":\"/opt/ml/input/data/valid_label\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"code\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train_data\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train_label\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid_data\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid_label\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mnist-tensor-plot-2020-06-16-22-03-06-879\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/input/data/code/sourcedir.tar.gz\",\"module_name\":\"mxnet_gluon_save_all_demo\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mxnet_gluon_save_all_demo.py\"}\u001b[0m\n",
            "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
            "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
            "\u001b[34mSM_CHANNEL_VALID_LABEL=/opt/ml/input/data/valid_label\u001b[0m\n",
            "\u001b[34mSM_CHANNEL_CODE=/opt/ml/input/data/code\u001b[0m\n",
            "\u001b[34mSM_CHANNEL_TRAIN_LABEL=/opt/ml/input/data/train_label\u001b[0m\n",
            "\u001b[34mSM_CHANNEL_VALID_DATA=/opt/ml/input/data/valid_data\u001b[0m\n",
            "\u001b[34mSM_CHANNEL_TRAIN_DATA=/opt/ml/input/data/train_data\u001b[0m\n",
            "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
            "\u001b[0m\n",
            "\u001b[34mInvoking script with the following command:\n",
            "\u001b[0m\n",
            "\u001b[34m/usr/local/bin/python3.6 mxnet_gluon_save_all_demo.py\n",
            "\n",
            "\u001b[0m\n",
            "\u001b[34mPreparing data ...\u001b[0m\n",
            "\u001b[34mtrain data path: /opt/ml/input/data/train_data\u001b[0m\n",
            "\u001b[34mtest data path: /opt/ml/input/data/valid_data\u001b[0m\n",
            "\u001b[34mtrain label path: /opt/ml/input/data/train_label\u001b[0m\n",
            "\u001b[34mtest label path: /opt/ml/input/data/valid_label\u001b[0m\n",
            "\u001b[34mData preparation done!\u001b[0m\n",
            "\u001b[34m[2020-06-16 22:06:43.430 ip-10-0-169-16.us-west-2.compute.internal:31 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
            "\u001b[34m[2020-06-16 22:06:43.431 ip-10-0-169-16.us-west-2.compute.internal:31 INFO hook.py:170] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
            "\u001b[34m[2020-06-16 22:06:43.431 ip-10-0-169-16.us-west-2.compute.internal:31 INFO hook.py:215] Saving to /opt/ml/output/tensors\u001b[0m\n",
            "\u001b[34m[2020-06-16 22:06:43.460 ip-10-0-169-16.us-west-2.compute.internal:31 INFO hook.py:351] Monitoring the collections: all_tensors, losses\u001b[0m\n",
            "\u001b[34m[2020-06-16 22:06:43.462 ip-10-0-169-16.us-west-2.compute.internal:31 WARNING hook.py:839] var is not NDArray or list or tuple of NDArrays, module_name:conv0_relu Symbol\u001b[0m\n",
            "\u001b[34m[2020-06-16 22:06:43.462 ip-10-0-169-16.us-west-2.compute.internal:31 WARNING hook.py:839] var is not NDArray or list or tuple of NDArrays, module_name:conv0_relu Symbol\u001b[0m\n",
            "\u001b[34m[2020-06-16 22:06:43.583 ip-10-0-169-16.us-west-2.compute.internal:31 WARNING hook.py:839] var is not NDArray or list or tuple of NDArrays, module_name:conv1_relu Symbol\u001b[0m\n",
            "\u001b[34m[2020-06-16 22:06:43.583 ip-10-0-169-16.us-west-2.compute.internal:31 WARNING hook.py:839] var is not NDArray or list or tuple of NDArrays, module_name:conv1_relu Symbol\u001b[0m\n",
            "\u001b[34m[2020-06-16 22:06:43.611 ip-10-0-169-16.us-west-2.compute.internal:31 WARNING hook.py:839] var is not NDArray or list or tuple of NDArrays, module_name:dense0_relu Symbol\u001b[0m\n",
            "\u001b[34m[2020-06-16 22:06:43.611 ip-10-0-169-16.us-west-2.compute.internal:31 WARNING hook.py:839] var is not NDArray or list or tuple of NDArrays, module_name:dense0_relu Symbol\u001b[0m\n",
            "\u001b[34m[2020-06-16 22:06:43.619 ip-10-0-169-16.us-west-2.compute.internal:31 WARNING hook.py:839] var is not NDArray or list or tuple of NDArrays, module_name:dense1_relu Symbol\u001b[0m\n",
            "\u001b[34m[2020-06-16 22:06:43.620 ip-10-0-169-16.us-west-2.compute.internal:31 WARNING hook.py:839] var is not NDArray or list or tuple of NDArrays, module_name:dense1_relu Symbol\u001b[0m\n",
            "\u001b[34m[2020-06-16 22:06:43.627 ip-10-0-169-16.us-west-2.compute.internal:31 INFO hook.py:226] Registering hook for block softmaxcrossentropyloss0\u001b[0m\n",
            "\u001b[34mERROR:root:'NoneType' object has no attribute 'write'\u001b[0m\n",
            "\n",
            "2020-06-16 22:07:05 Uploading - Uploading generated training model\n",
            "2020-06-16 22:07:05 Completed - Training job completed\n",
            "\u001b[34mEpoch 0: loss 0.415, train acc 0.871, test acc 0.084, in 16.7 sec\u001b[0m\n",
            "\u001b[34m[2020-06-16 22:06:59.446 ip-10-0-169-16.us-west-2.compute.internal:31 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
            "\u001b[34m2020-06-16 22:06:59,703 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
            "Training seconds: 92\n",
            "Billable seconds: 92\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get S3 location of tensors"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can retrieve the S3 location of the tensors:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "tensors_path = estimator.latest_job_debugger_artifacts_path()\n",
        "print('S3 location of tensors is: ', tensors_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S3 location of tensors is:  s3://sagemaker-bhan-dev/mnist-tensor-plot/mnist-tensor-plot-2020-06-16-22-03-06-879/debug-output\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download tensors from S3\n",
        "\nNext we download the tensors from S3, so that we can visualize them in the notebook."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "folder_name = tensors_path.split(\"/\")[-1]\n",
        "os.system(\"aws s3 cp --recursive \" + tensors_path + \" \" + folder_name)\n",
        "print('Downloaded tensors into folder: ', folder_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded tensors into folder:  debug-output\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize\n",
        "The main purpose of this class (TensorPlot) is to visualise the tensors in your network. This could be to determine dead or saturated activations, or the features maps the network.\n",
        "\n",
        "To use this class (TensorPlot), you will need to supply the argument regex with the tensors you are interested in. e.g., if you are interested in activation outputs, then you need to supply the following regex .*relu|.*tanh|.*sigmoid.\n",
        "\n",
        "Another important argument is the `sample_batch_id`, which allows you to specify the index of the batch size to display. For example, given an input tensor of size (batch_size, channel, width, height), `sample_batch_id = n` will display (n, channel, width, height). If you set sample_batch_id = -1 then the tensors will be summed over the batch dimension (i.e., `np.sum(tensor, axis=0)`). If batch_sample_id is None then each sample will be plotted as separate layer in the figure.\n",
        "\n",
        "Here are some interesting use cases:\n",
        "\n",
        "1) If you want to determine dead or saturated activations for instance ReLus that are always outputting zero, then you would want to sum the batch dimension (sample_batch_id=-1). The sum gives an indication which parts of the network are inactive across a batch.\n",
        "\n",
        "2) If you are interested in the feature maps for the first image in the batch, then you should provide batch_sample_id=0. This can be helpful if your model is not performing well for certain set of samples and you want to understand which activations are leading to misprediction.\n",
        "\n",
        "An example visualization of layer outputs:\n",
        "![](./images/tensorplot.gif)\n",
        "\n\n",
        "`TensorPlot` normalizes tensor values to the range 0 to 1 which means colorscales are the same across layers. Blue indicates value close to 0 and yellow indicates values close to 1. This class has been designed to plot convolutional networks that take 2D images as input and predict classes or produce output images. You can use this  for other types of networks like RNNs, but you may have to adjust the class as it is currently neglecting tensors that have more than 4 dimensions.\n",
        "\nLet's plot Relu output activations for the given MNIST training example."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import tensor_plot \n",
        "\n",
        "visualization = tensor_plot.TensorPlot(\n",
        "    regex=\".*relu_output\", \n",
        "    path=folder_name,\n",
        "    steps=10,  \n",
        "    batch_sample_id=0,\n",
        "    color_channel = 1,\n",
        "    title=\"Relu outputs\",\n",
        "    label=\".*sequential0_input_0\",\n",
        "    prediction=\".*sequential0_output_0\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2020-06-16 22:07:21.577 ip-10-10-60-246:6974 INFO local_trial.py:35] Loading trial debug-output at path debug-output\n",
            "[2020-06-16 22:07:21.582 ip-10-10-60-246:6974 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
            "[2020-06-16 22:07:22.585 ip-10-10-60-246:6974 INFO trial.py:210] Loaded all steps\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we plot too many layers, it can crash the notebook. If you encounter performance or out of memory issues, then either try to reduce the layers to plot by changing the `regex` or run this Notebook in JupyterLab instead of Jupyter. \n",
        "\nIn the below cell we vizualize outputs of all layers, including final classification. Please note that because training job ran only for 1 epoch classification accuracy is not high."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "visualization.fig.show(renderer=\"iframe\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<iframe\n",
              "    scrolling=\"no\"\n",
              "    width=\"1020px\"\n",
              "    height=\"820\"\n",
              "    src=\"iframe_figures/figure_8.html\"\n",
              "    frameborder=\"0\"\n",
              "    allowfullscreen\n",
              "></iframe>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "For additional example of working with debugging tensors and visualizing them in real time please feel free to try it out at [MXNet realtime analysis](../mxnet_realtime_analysis/mxnet-realtime-analysis.ipynb) example."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "conda_mxnet_p36",
      "language": "python",
      "name": "conda_mxnet_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}